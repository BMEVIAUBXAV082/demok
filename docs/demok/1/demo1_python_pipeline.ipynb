{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 1: Teljes Data Engineering pipeline Python-ban\n",
    "\n",
    "**BME Adatm\u00e9rn\u00f6ki alapok \u2013 1. h\u00e9t**\n",
    "\n",
    "Ez a dem\u00f3 bemutatja a teljes Data Engineering \u00e9letciklust (Gener\u00e1l\u00e1s \u2192 Bevitel \u2192 T\u00e1rol\u00e1s \u2192 Transzform\u00e1ci\u00f3 \u2192 Kiszolg\u00e1l\u00e1s) kiz\u00e1r\u00f3lag Python haszn\u00e1lat\u00e1val, Google Colab-on futtathat\u00f3an, Docker n\u00e9lk\u00fcl.\n",
    "\n",
    "**Tartom\u00e1ny:** Id\u0151j\u00e1r\u00e1s/IoT \u2013 magyar v\u00e1rosok h\u0151m\u00e9rs\u00e9klet-elemz\u00e9se\n",
    "\n",
    "```\n",
    "Gener\u00e1l\u00e1s \u2192 Bevitel (Ingestion) \u2192 T\u00e1rol\u00e1s \u2192 Transzform\u00e1ci\u00f3 \u2192 Kiszolg\u00e1l\u00e1s (Serving)\n",
    "                                                    \u2195\n",
    "                                              Adatmin\u0151s\u00e9g (Undercurrents)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Csomagok telep\u00edt\u00e9se (Colab-on futtatva)\n",
    "!pip install -q faker requests pandas matplotlib seaborn\n",
    "\n",
    "import faker\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Magyar locale \u00e9s st\u00edlus\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Csomagok bet\u00f6ltve!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gener\u00e1l\u00e1s (Generation)\n",
    "\n",
    "A Faker k\u00f6nyvt\u00e1r seg\u00edts\u00e9g\u00e9vel 10 id\u0151j\u00e1r\u00e1s-\u00e1llom\u00e1s metaadatait gener\u00e1ljuk magyar v\u00e1rosokhoz.\n",
    "Ez reprezent\u00e1lja a \u201eforr\u00e1srendszert\u201d (source system), amely az adatokat el\u0151\u00e1ll\u00edtja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. GENER\u00c1L\u00c1S: Id\u0151j\u00e1r\u00e1s-\u00e1llom\u00e1sok metaadatai ===\n",
    "from faker import Faker\n",
    "fake = Faker('hu_HU')\n",
    "\n",
    "# Magyar v\u00e1rosok val\u00f3s koordin\u00e1t\u00e1kkal\n",
    "cities = [\n",
    "    {\"city\": \"Budapest\",  \"lat\": 47.4979, \"lon\": 19.0402, \"elevation\": 96},\n",
    "    {\"city\": \"Debrecen\",  \"lat\": 47.5316, \"lon\": 21.6273, \"elevation\": 121},\n",
    "    {\"city\": \"Szeged\",    \"lat\": 46.2530, \"lon\": 20.1414, \"elevation\": 75},\n",
    "    {\"city\": \"Miskolc\",   \"lat\": 48.1035, \"lon\": 20.7784, \"elevation\": 130},\n",
    "    {\"city\": \"P\u00e9cs\",      \"lat\": 46.0727, \"lon\": 18.2323, \"elevation\": 153},\n",
    "    {\"city\": \"Gy\u0151r\",      \"lat\": 47.6875, \"lon\": 17.6504, \"elevation\": 108},\n",
    "    {\"city\": \"Ny\u00edregyh\u00e1za\",\"lat\": 47.9554, \"lon\": 21.7167, \"elevation\": 118},\n",
    "    {\"city\": \"Kecskem\u00e9t\", \"lat\": 46.9063, \"lon\": 19.6897, \"elevation\": 120},\n",
    "    {\"city\": \"Sz\u00e9kesfeh\u00e9rv\u00e1r\",\"lat\": 47.1860, \"lon\": 18.4221, \"elevation\": 110},\n",
    "    {\"city\": \"Sopron\",    \"lat\": 47.6817, \"lon\": 16.5845, \"elevation\": 214},\n",
    "]\n",
    "\n",
    "stations_df = pd.DataFrame(cities)\n",
    "stations_df['station_id'] = [f\"HU-{i+1:03d}\" for i in range(len(cities))]\n",
    "stations_df['installed'] = [fake.date_between(start_date='-5y', end_date='-1y') for _ in range(len(cities))]\n",
    "\n",
    "print(f\"Gener\u00e1lt \u00e1llom\u00e1sok sz\u00e1ma: {len(stations_df)}\")\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bevitel \u2013 Ingestion (Pull minta: REST API)\n",
    "\n",
    "Az Open-Meteo API seg\u00edts\u00e9g\u00e9vel (ingyenes, nem ig\u00e9nyel API kulcsot) 30 nap \u00f3r\u00e1nk\u00e9nti id\u0151j\u00e1r\u00e1s-adatait k\u00e9rj\u00fck le minden \u00e1llom\u00e1shoz.\n",
    "Ez egy **Pull ingestion** minta \u2013 akt\u00edvan lek\u00e9rj\u00fck az adatokat a forr\u00e1sb\u00f3l REST API-n kereszt\u00fcl.\n",
    "\n",
    "> **API info:** [Open-Meteo](https://open-meteo.com/) \u2013 Nyilv\u00e1nos, ingyenes meteorol\u00f3giai API. Nincs sz\u00fcks\u00e9g regisztr\u00e1ci\u00f3ra vagy API kulcsra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. INGESTION: Open-Meteo API \u2013 30 nap \u00f3r\u00e1nk\u00e9nti adatok ===\n",
    "BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "all_weather = []\n",
    "for _, station in stations_df.iterrows():\n",
    "    params = {\n",
    "        \"latitude\": station[\"lat\"],\n",
    "        \"longitude\": station[\"lon\"],\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m,wind_speed_10m,precipitation\",\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"timezone\": \"Europe/Budapest\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        hourly = data[\"hourly\"]\n",
    "\n",
    "        for i in range(len(hourly[\"time\"])):\n",
    "            all_weather.append({\n",
    "                \"station_id\": station[\"station_id\"],\n",
    "                \"timestamp\": hourly[\"time\"][i],\n",
    "                \"temperature_c\": hourly[\"temperature_2m\"][i],\n",
    "                \"humidity_pct\": hourly[\"relative_humidity_2m\"][i],\n",
    "                \"wind_speed_kmh\": hourly[\"wind_speed_10m\"][i],\n",
    "                \"precipitation_mm\": hourly[\"precipitation\"][i],\n",
    "            })\n",
    "        print(f\"  {station['city']:20s} \u2013 {len(hourly['time']):5d} m\u00e9r\u00e9s bet\u00f6ltve\")\n",
    "    else:\n",
    "        print(f\"  {station['city']:20s} \u2013 HIBA: {response.status_code}\")\n",
    "\n",
    "weather_df = pd.DataFrame(all_weather)\n",
    "weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "print(f\"\\n\u00d6sszesen {len(weather_df):,} m\u00e9r\u00e9si adat bet\u00f6ltve ({len(stations_df)} \u00e1llom\u00e1s \u00d7 ~{len(weather_df)//len(stations_df)} \u00f3ra)\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. T\u00e1rol\u00e1s (Storage) \u2013 SQLite adatb\u00e1zis\n",
    "\n",
    "Az adatokat SQLite adatb\u00e1zisban t\u00e1roljuk \u2013 ez egy k\u00f6nny\u0171s\u00faly\u00fa rel\u00e1ci\u00f3s adatb\u00e1zis.\n",
    "\u00c9les k\u00f6rnyezetben ez PostgreSQL, data lake vagy m\u00e1s megold\u00e1s lehetne.\n",
    "L\u00e9trehozunk egy \u201enyers z\u00f3n\u00e1t\u201d (raw zone), ahov\u00e1 az eredeti adatokat mentj\u00fck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. STORAGE: SQLite adatb\u00e1zis (raw z\u00f3na) ===\n",
    "DB_PATH = \"weather_pipeline.db\"\n",
    "\n",
    "# T\u00f6r\u00f6lj\u00fck a kor\u00e1bbi DB-t ha l\u00e9tezik\n",
    "if os.path.exists(DB_PATH):\n",
    "    os.remove(DB_PATH)\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# T\u00e1bl\u00e1k l\u00e9trehoz\u00e1sa\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE stations (\n",
    "        station_id TEXT PRIMARY KEY,\n",
    "        city TEXT NOT NULL,\n",
    "        latitude REAL,\n",
    "        longitude REAL,\n",
    "        elevation INTEGER,\n",
    "        installed DATE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE raw_weather (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        station_id TEXT REFERENCES stations(station_id),\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        temperature_c REAL,\n",
    "        humidity_pct REAL,\n",
    "        wind_speed_kmh REAL,\n",
    "        precipitation_mm REAL\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Adatok bet\u00f6lt\u00e9se\n",
    "stations_df.to_sql(\"stations\", conn, if_exists=\"replace\", index=False)\n",
    "weather_df.to_sql(\"raw_weather\", conn, if_exists=\"replace\", index=False)\n",
    "conn.commit()\n",
    "\n",
    "# Ellen\u0151rz\u00e9s\n",
    "station_count = pd.read_sql(\"SELECT COUNT(*) as cnt FROM stations\", conn).iloc[0, 0]\n",
    "weather_count = pd.read_sql(\"SELECT COUNT(*) as cnt FROM raw_weather\", conn).iloc[0, 0]\n",
    "print(f\"SQLite adatb\u00e1zis l\u00e9trehozva: {DB_PATH}\")\n",
    "print(f\"  stations t\u00e1bla:    {station_count:>8,} sor\")\n",
    "print(f\"  raw_weather t\u00e1bla: {weather_count:>8,} sor\")\n",
    "print(f\"  DB m\u00e9ret:          {os.path.getsize(DB_PATH) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transzform\u00e1ci\u00f3 (Transformation)\n",
    "\n",
    "Itt tiszt\u00edtjuk, gazdag\u00edtjuk \u00e9s aggreg\u00e1ljuk a nyers adatokat. L\u00e9p\u00e9sek:\n",
    "1. **Adattiszt\u00edt\u00e1s** \u2013 null \u00e9rt\u00e9kek kezel\u00e9se, outlier sz\u0171r\u00e9s\n",
    "2. **JOIN** \u2013 \u00e1llom\u00e1s metaadatokkal val\u00f3 \u00f6sszekapcsol\u00e1s\n",
    "3. **Napi aggreg\u00e1ci\u00f3** \u2013 \u00f3r\u00e1nk\u00e9nti adatokb\u00f3l napi statisztik\u00e1k\n",
    "4. **Feature engineering** \u2013 mozg\u00f3\u00e1tlag, h\u0151ing\u00e1s\n",
    "5. **Anom\u00e1lia detekci\u00f3** \u2013 z-score alap\u00fa kil\u00f3g\u00f3 \u00e9rt\u00e9kek azonos\u00edt\u00e1sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. TRANSZFORM\u00c1CI\u00d3 ===\n",
    "\n",
    "# 4.1 \u2013 Bet\u00f6lt\u00e9s SQLite-b\u00f3l\n",
    "raw = pd.read_sql(\"\"\"\n",
    "    SELECT w.*, s.city, s.elevation\n",
    "    FROM raw_weather w\n",
    "    JOIN stations s ON w.station_id = s.station_id\n",
    "\"\"\", conn)\n",
    "raw[\"timestamp\"] = pd.to_datetime(raw[\"timestamp\"])\n",
    "\n",
    "print(f\"Bet\u00f6lt\u00f6tt sorok: {len(raw):,}\")\n",
    "print(f\"Null \u00e9rt\u00e9kek:\\n{raw.isnull().sum()}\")\n",
    "\n",
    "# 4.2 \u2013 Tiszt\u00edt\u00e1s: null kezel\u00e9s, outlier sz\u0171r\u00e9s\n",
    "raw = raw.dropna(subset=[\"temperature_c\"])\n",
    "raw = raw[(raw[\"temperature_c\"] > -40) & (raw[\"temperature_c\"] < 50)]\n",
    "raw = raw[(raw[\"humidity_pct\"] >= 0) & (raw[\"humidity_pct\"] <= 100)]\n",
    "print(f\"\\nTiszt\u00edt\u00e1s ut\u00e1n: {len(raw):,} sor\")\n",
    "\n",
    "# 4.3 \u2013 Napi aggreg\u00e1ci\u00f3\n",
    "raw[\"date\"] = raw[\"timestamp\"].dt.date\n",
    "daily = raw.groupby([\"station_id\", \"city\", \"date\"]).agg(\n",
    "    avg_temp=(\"temperature_c\", \"mean\"),\n",
    "    min_temp=(\"temperature_c\", \"min\"),\n",
    "    max_temp=(\"temperature_c\", \"max\"),\n",
    "    avg_humidity=(\"humidity_pct\", \"mean\"),\n",
    "    avg_wind=(\"wind_speed_kmh\", \"mean\"),\n",
    "    total_precip=(\"precipitation_mm\", \"sum\"),\n",
    "    measurement_count=(\"temperature_c\", \"count\")\n",
    ").reset_index()\n",
    "daily[\"date\"] = pd.to_datetime(daily[\"date\"])\n",
    "\n",
    "# 4.4 \u2013 Feature engineering: mozg\u00f3\u00e1tlag, napi h\u0151ing\u00e1s\n",
    "daily[\"temp_7d_mavg\"] = daily.groupby(\"city\")[\"avg_temp\"].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean()\n",
    ")\n",
    "daily[\"temp_range\"] = daily[\"max_temp\"] - daily[\"min_temp\"]\n",
    "\n",
    "# 4.5 \u2013 Anom\u00e1lia detekci\u00f3 (z-score alap\u00fa)\n",
    "city_stats = daily.groupby(\"city\")[\"avg_temp\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "city_stats.columns = [\"city\", \"city_mean\", \"city_std\"]\n",
    "daily = daily.merge(city_stats, on=\"city\")\n",
    "daily[\"z_score\"] = (daily[\"avg_temp\"] - daily[\"city_mean\"]) / daily[\"city_std\"]\n",
    "daily[\"is_anomaly\"] = daily[\"z_score\"].abs() > 2.0\n",
    "\n",
    "print(f\"\\nNapi aggreg\u00e1ci\u00f3: {len(daily):,} sor\")\n",
    "print(f\"Anom\u00e1li\u00e1k sz\u00e1ma: {daily['is_anomaly'].sum()}\")\n",
    "print(f\"\\nV\u00e1rosi statisztik\u00e1k:\")\n",
    "print(daily.groupby(\"city\")[[\"avg_temp\", \"total_precip\"]].mean().round(1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kiszolg\u00e1l\u00e1s (Serving) \u2013 Vizualiz\u00e1ci\u00f3\n",
    "\n",
    "Az utols\u00f3 f\u00e1zis \u2013 az adatok kiszolg\u00e1l\u00e1sa a v\u00e9gfelhaszn\u00e1l\u00f3knak.\n",
    "\u00c9les k\u00f6rnyezetben ez lehetne dashboard (Tableau, PowerBI), API v\u00e9gpont, vagy ML modell bemenet.\n",
    "Mi egy 4 paneles analitikai dashboard-ot k\u00e9sz\u00edt\u00fcnk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. SERVING: Analitikai dashboard ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(\"Id\u0151j\u00e1r\u00e1s-elemz\u00e9s \u2013 Magyar v\u00e1rosok (utols\u00f3 30 nap)\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# --- 5.1 H\u0151m\u00e9rs\u00e9klet trend (top 5 v\u00e1ros) ---\n",
    "ax1 = axes[0, 0]\n",
    "top_cities = [\"Budapest\", \"Debrecen\", \"Szeged\", \"P\u00e9cs\", \"Sopron\"]\n",
    "for city in top_cities:\n",
    "    city_data = daily[daily[\"city\"] == city].sort_values(\"date\")\n",
    "    ax1.plot(city_data[\"date\"], city_data[\"temp_7d_mavg\"], label=city, linewidth=2)\n",
    "ax1.set_title(\"H\u0151m\u00e9rs\u00e9klet trend (7 napos mozg\u00f3\u00e1tlag)\")\n",
    "ax1.set_ylabel(\"H\u0151m\u00e9rs\u00e9klet (\u00b0C)\")\n",
    "ax1.legend(loc=\"upper left\", fontsize=8)\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m.%d'))\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 5.2 \u00c1tlagh\u0151m\u00e9rs\u00e9klet v\u00e1rosonk\u00e9nt (barplot) ---\n",
    "ax2 = axes[0, 1]\n",
    "city_avg = daily.groupby(\"city\")[\"avg_temp\"].mean().sort_values(ascending=True)\n",
    "colors = sns.color_palette(\"coolwarm\", len(city_avg))\n",
    "bars = ax2.barh(city_avg.index, city_avg.values, color=colors)\n",
    "ax2.set_title(\"\u00c1tlagos h\u0151m\u00e9rs\u00e9klet v\u00e1rosonk\u00e9nt\")\n",
    "ax2.set_xlabel(\"H\u0151m\u00e9rs\u00e9klet (\u00b0C)\")\n",
    "for bar, val in zip(bars, city_avg.values):\n",
    "    ax2.text(val + 0.1, bar.get_y() + bar.get_height()/2, f\"{val:.1f}\u00b0C\", va='center', fontsize=8)\n",
    "\n",
    "# --- 5.3 H\u0151m\u00e9rs\u00e9klet heatmap ---\n",
    "ax3 = axes[1, 0]\n",
    "pivot = daily.pivot_table(index=\"city\", columns=\"date\", values=\"avg_temp\")\n",
    "# D\u00e1tum c\u00edmk\u00e9k egyszer\u0171s\u00edt\u00e9se\n",
    "pivot.columns = [d.strftime(\"%m.%d\") for d in pivot.columns]\n",
    "# Csak minden N-edik c\u00edmke megjelen\u00edt\u00e9se\n",
    "n_cols = len(pivot.columns)\n",
    "show_every = max(1, n_cols // 10)\n",
    "sns.heatmap(pivot, ax=ax3, cmap=\"RdYlBu_r\", cbar_kws={\"label\": \"\u00b0C\"},\n",
    "            xticklabels=show_every)\n",
    "ax3.set_title(\"H\u0151m\u00e9rs\u00e9klet heatmap (v\u00e1ros \u00d7 nap)\")\n",
    "ax3.set_xlabel(\"\")\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# --- 5.4 Csapad\u00e9k \u00f6sszehasonl\u00edt\u00e1s ---\n",
    "ax4 = axes[1, 1]\n",
    "precip_total = daily.groupby(\"city\")[\"total_precip\"].sum().sort_values(ascending=False)\n",
    "ax4.bar(range(len(precip_total)), precip_total.values, color=sns.color_palette(\"Blues_r\", len(precip_total)))\n",
    "ax4.set_xticks(range(len(precip_total)))\n",
    "ax4.set_xticklabels(precip_total.index, rotation=45, ha=\"right\")\n",
    "ax4.set_title(\"\u00d6sszes csapad\u00e9k (30 nap)\")\n",
    "ax4.set_ylabel(\"Csapad\u00e9k (mm)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"weather_dashboard.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Dashboard mentve: weather_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adatmin\u0151s\u00e9g (Undercurrents)\n",
    "\n",
    "Az adatmin\u0151s\u00e9g az egyik \u201eundercurrent\u201d, amely az \u00e9letciklus minden f\u00e1zis\u00e1t \u00e1thatja.\n",
    "Alapvet\u0151 min\u0151s\u00e9gi ellen\u0151rz\u00e9seket v\u00e9gz\u00fcnk: teljes\u00e9g, frissess\u00e9g, tartom\u00e1ny-valid\u00e1ci\u00f3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. ADATMIN\u0150S\u00c9G (Undercurrents) ===\n",
    "print(\"=\" * 60)\n",
    "print(\"ADATMIN\u0150S\u00c9GI JELENT\u00c9S\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# 6.1 \u2013 Teljess\u00e9g (Completeness)\n",
    "total_expected = len(stations_df) * 31 * 24  # 10 \u00e1llom\u00e1s \u00d7 31 nap \u00d7 24 \u00f3ra\n",
    "total_actual = len(weather_df)\n",
    "completeness = total_actual / total_expected * 100\n",
    "passed = completeness > 95\n",
    "checks.append((\"Teljess\u00e9g (completeness)\", f\"{completeness:.1f}%\", \"PASS\" if passed else \"FAIL\"))\n",
    "print(f\"\\n1. Teljess\u00e9g: {total_actual:,} / {total_expected:,} = {completeness:.1f}% {chr(10003) if passed else chr(10007)}\")\n",
    "\n",
    "# 6.2 \u2013 Frissess\u00e9g (Freshness)\n",
    "latest = weather_df[\"timestamp\"].max()\n",
    "freshness_hours = (datetime.now() - latest).total_seconds() / 3600\n",
    "passed = freshness_hours < 48\n",
    "checks.append((\"Frissess\u00e9g (freshness)\", f\"{freshness_hours:.0f} \u00f3ra\", \"PASS\" if passed else \"FAIL\"))\n",
    "print(f\"2. Frissess\u00e9g: legut\u00f3bbi adat {freshness_hours:.0f} \u00f3r\u00e1ja {chr(10003) if passed else chr(10007)}\")\n",
    "\n",
    "# 6.3 \u2013 Tartom\u00e1ny (Range validation)\n",
    "temp_min, temp_max = weather_df[\"temperature_c\"].min(), weather_df[\"temperature_c\"].max()\n",
    "passed = temp_min > -50 and temp_max < 60\n",
    "checks.append((\"H\u0151m\u00e9rs\u00e9klet tartom\u00e1ny\", f\"[{temp_min:.1f}, {temp_max:.1f}]\u00b0C\", \"PASS\" if passed else \"FAIL\"))\n",
    "print(f\"3. H\u0151m\u00e9rs\u00e9klet tartom\u00e1ny: [{temp_min:.1f}, {temp_max:.1f}]\u00b0C {chr(10003) if passed else chr(10007)}\")\n",
    "\n",
    "# 6.4 \u2013 Null ar\u00e1ny\n",
    "null_pct = weather_df.isnull().mean() * 100\n",
    "max_null = null_pct.max()\n",
    "passed = max_null < 5\n",
    "checks.append((\"Null ar\u00e1ny (max)\", f\"{max_null:.2f}%\", \"PASS\" if passed else \"FAIL\"))\n",
    "print(f\"4. Maxim\u00e1lis null ar\u00e1ny: {max_null:.2f}% {chr(10003) if passed else chr(10007)}\")\n",
    "\n",
    "# 6.5 \u2013 Egyedis\u00e9g (\u00e1llom\u00e1sok)\n",
    "unique_stations = weather_df[\"station_id\"].nunique()\n",
    "passed = unique_stations == len(stations_df)\n",
    "checks.append((\"Egyedi \u00e1llom\u00e1sok\", f\"{unique_stations}/{len(stations_df)}\", \"PASS\" if passed else \"FAIL\"))\n",
    "print(f\"5. Egyedi \u00e1llom\u00e1sok: {unique_stations}/{len(stations_df)} {chr(10003) if passed else chr(10007)}\")\n",
    "\n",
    "# \u00d6sszes\u00edt\u00e9s\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "pass_count = sum(1 for c in checks if c[2] == \"PASS\")\n",
    "print(f\"Eredm\u00e9ny: {pass_count}/{len(checks)} ellen\u0151rz\u00e9s SIKERES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cleanup\n",
    "conn.close()\n",
    "if os.path.exists(DB_PATH):\n",
    "    os.remove(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u00d6sszefoglal\u00e1s\n",
    "\n",
    "| DE Lifecycle f\u00e1zis | Megval\u00f3s\u00edt\u00e1s | Python eszk\u00f6z |\n",
    "|---|---|---|\n",
    "| Gener\u00e1l\u00e1s | \u00c1llom\u00e1s metaadatok | Faker |\n",
    "| Bevitel (Ingestion) | REST API lek\u00e9r\u00e9s | requests (Pull minta) |\n",
    "| T\u00e1rol\u00e1s (Storage) | SQLite adatb\u00e1zis | sqlite3 |\n",
    "| Transzform\u00e1ci\u00f3 | Tiszt\u00edt\u00e1s, aggreg\u00e1ci\u00f3, feature eng. | pandas |\n",
    "| Kiszolg\u00e1l\u00e1s (Serving) | Dashboard vizualiz\u00e1ci\u00f3 | matplotlib, seaborn |\n",
    "| Adatmin\u0151s\u00e9g | Min\u0151s\u00e9gi ellen\u0151rz\u00e9sek | assertions |\n",
    "\n",
    "---\n",
    "\n",
    "Ez a teljes pipeline **pure Python-ban** futott, Docker \u00e9s felh\u0151szolg\u00e1ltat\u00e1s n\u00e9lk\u00fcl.\n",
    "\u00c9les k\u00f6rnyezetben ezeket az eszk\u00f6z\u00f6ket modern, sk\u00e1l\u00e1zhat\u00f3 megold\u00e1sokkal helyettes\u00edtj\u00fck \u2013 ezt mutatja a 2. dem\u00f3."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}